---
title: "Assignment 1 - Group 8"
author: "Elia Di Gregorio and Robert Auerbach"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
papersize: a4
urlcolor: blue
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

source("./code/__packages.R")
load("./Workspace_AB.RData")
```

# Exercise A
The dependent variable `medv` shows the median value of owner-occupied homes in $1000s.
We chose the following covariates for our linear model:
1) `crim`: per capita crime rate by town.
2) `zn`: proportion of residential land zoned for lots over 25,000 sq.ft.
3) `indus`: proportion of non-retail business acres per town.
4) `chas`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
5) `nox`: nitrogen oxides concentration (parts per 10 million).

Task: Create a function that takes your dependent variable and the covariates as inputs,
and return a list with:
– OLS point estimates for the intercept, slope parameters, and the error variance.
– Suitable test statistics with corresponding p-values for the relevant coefficients.
– Intervals of the coefficients for a confidence level of 95%.

```{r}
pp_pred <- function(dependent_variable, covariates) {
  data <- data.frame(dependent_variable, covariates)
  model <- lm(dependent_variable ~ ., data)
  coefficients <- coef(model)
  se <- summary(model)$coefficients[, "Std. Error"]
  t_values <- coefficients / se
  p_values <- 2 * pt(abs(t_values), df = df.residual(model), lower.tail = FALSE)
  conf_int <- confint.default(model)
  results <- data.frame(
    "Coefficients" = coefficients,
    "Standard Errors" = se,
    "t-values" = t_values,
    "p-values" = p_values,
    "Confidence Intervals (95%)" = conf_int
  )
  
  return(results)
}
```

Call the function and print list:

```{r}
result <- property_price_prediction(dependent_variable, covariates)
print(result)
```

# Exercise B

Task: Come up with some network of interest, vaguely related to some real-world example
(describe very briefly), with at least six agents and ten edges between them.

Our real world example is one of a supply chain network where there is rarely any reciprocity: construction of airplanes. The main vertices is the firm constructing the airplane (B), where all manufactured parts end up (high in-degree, low out-degree). On the other hand, among manufactures of airplane parts little reciprocity might occur as they need specialized part to finish their own parts (D and A).

The adjacency matrix in R.can be drawn as follows: 

```{r}
plot(g, edge.arrow.size = 0.5, vertex.label.cex = 1.5, vertex.size = 30)

print(adj_matrix)
```

Who are the most and least central agents in the network? Name, explain, and try
to quantify different notions of centrality.

We quantified the in- and out-degree of centrality. The in-degree shows how many links are directed towards are node, while the out-degree shows how many links are directed from a node (to another). A node from which a link goes out to another is considered a supplier, a node which is receiving links is considered a buyer.
The degree_table shows how many links go in and out from each node. This way we can quantify the most central buyer and supplier in our network.
According to the table B and D have the most links directed towards them while E has none directed towards it. Hence, B and C are the most central "buyers", E the least.
Also, A and D have the most links directed towards others while B has none directed towards others. Hence A and D are the most central "suppliers" and B the least.

```{r}
degree_table
```

How would centrality change if you considered a row-normalized network instead?

We calculate the sums of each row of the adjacency matrix and then divide the addjacency matrix by the row sums.
Again, we compute the centrality measures of in- and out-degree. As expected (based on the slides) the out-degree of the agents are equalized to 1. Also, the most central buyers are now B and D instead of B and C. Clearly the row-normalization leads to a distortion.

```{r}
degree_table_norm
```

How would the network change if you removed or added a specific agent?
We removed agent "F" and repeated the steps from above.

The most central buyer is now B alone, E still is the least central buyer.
The most central supplier is still A and D, the least is still B.

We also compared the reciprocity and transitivity of both networks. The reciprocity is higher with the agent F removed, which is due to the fact that the network has a higher share of reciprocated links relative to the amount of possible reciprocated links. Also, the so called clustering coefficient (Transitivity) is higher in the Network with fewer agents as there is a 10% higher probability that vertices are connected. This is especially true for a network with low reciprocity such as ours.

```{r}
plot(g1, edge.arrow.size = 0.5, vertex.label.cex = 1.5, vertex.size = 30)
degree_table_g1
rectrans_table
```

Simulating some agent characteristic:
For our real world example we choose level of experience as the agent characteristic and number of defects as the response variable. The coefficient beta we choose to be -0.8 indicating that more experience leads to less defects. We assign some values to the other parameters gamma, lamda and sigma^2 as indicated in the code.

The linear model estimate depicts a larger negative relationship between level of experience and number of defects than we initially set (-0.8). Hence, there is a bias present.
```{r}
# 1. Set parameters
lambda <- 0.4  # Parameter for the network effect
beta <- -0.8     # Coefficient for the direct effect of X
theta <- 0.5   # Coefficient for the network-lagged effect of X

# 2. Simulate data
N <- 6  # Number of agents
W <- adj_matrix  # Assuming adj_matrix is already defined

# Generate random values for the level of experience (X)
x <- rnorm(nrow(W), 0, 1)

# Generate random errors
errs <- rnorm(N, 0, 1)

# Calculate the network-lagged effect of X (W %*% x)
WX_theta <- W %*% x * theta

# Calculate the right-hand side of the equation (λWy + Xβ + WXθ + e)
rhs <- lambda * (W %*% y) + x * beta + WX_theta + errs

# Solve for the response variable (y) using the reduced form of the equation
y <- solve(diag(N) - lambda * W, rhs)

# Check the result
print(y)

y <- as.matrix(y)

model_1 <- lm(y ~ x)
estimate[i] <- coef(model_1)["x"]

estimate_mean <- mean(estimate)
print(estimate_mean)


```


\newpage


# Exercise C
In this exercise, we will work with spatial projections of Europe's NUTS-2 regions. Europe counts 331 subregions, however we excluded overseas territories and focused on the main continental area to improve the final visualization.

## Different projections
We accessed its spatial data directly from the [GISCO](https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts) source via `get_eurostat_spatial()` function. By default this function loads the EPSG-4326 projection of the map, corresponding to the World Geodetic System 1984 ensemble (WGS84). It is based on a geocentric datum, meaning it defines the Earth's shape as an ellipsoid (a flattened sphere) rather than a perfect sphere.

```{r Europe sf}
Europe <- get_eurostat_geospatial(
  resolution = "01",
  nuts_level = 2,
  year = 2021) %>%
  filter(!NUTS_ID %in% c("FRY1", "FRY2", "FRY3", "FRY4", "FRY5", "FRZZ",
                         "PT20", "PT30", "PTZZ", "ES70", "ESZZ", "NO0B", "NOZZ"))

st_crs(Europe)
```

To use another projection and/or CRS we employed the `st_transform()` function and recurred to the Lambert Azimuthal Equal Area Projection. It preserve the relative sizes of areas on the Earth's surface. This means that areas on the map are represented accurately in relation to each other in terms of size, making it suitable for thematic mapping and spatial analysis. However it projects the Earth's surface onto a plane tangent to a specific point (the center of the projection).
The difference in projections is highlighted by the following map:

```{r Europe Projection}
plot_Europe <- ggplot() +
  geom_sf(data = Europe, color = "black", fill = NA) +
  theme_minimal() +
  labs(title = "WGS 84 Projection", size = 12)

Europe_laea <- st_transform(Europe, crs = "+proj=laea +lat_0=45 +lon_0=30")
plot_laea <- ggplot() +
  geom_sf(data = Europe_laea, color = "darkblue", fill = NA) +
  theme_minimal() +
  labs(title = "Lambert Azimuthal Projection", size = 12)

EU_plot_1 <- plot_Europe + plot_laea +
  plot_layout(ncol = 2) +
  labs(caption="Source: Eurostat")

plot(EU_plot_1)
```

## Map and Dataset
The dataset used was `tgs00111`: Nights spent at tourist accommodation establishments by NUTS 2 regions ([here](<https://ec.europa.eu/eurostat/cache/metadata/en/tour_occ_esms.htm) the Metadata for consultation). The dataset covers internal tourism, in other words tourism flows within the country (domestic tourism) or from abroad to destinations in the country (inbound tourism) for the year 2022. We further enhanced the dataset with two additional columns with the share of domestic and foreign tourist overnights (continuous scale), and one column for a factor variable based on the condition that if the domestic tourism share of overnight stay is greater than 50%, the tourist is labeled as "Domestic Tourist"; otherwise, they are labeled as "Foreign Tourist" (discrete scale).

```{r Dataset from Eurostat}
data_nightstay <- get_eurostat("tgs00111",
                               time_format = "raw",
                               filters = list(
                                 TIME_PERIOD = "2022"
                               )) %>% 
  merge(.,Europe, by = "geo", all=TRUE) %>%
  filter(!NUTS_ID %in% c("FRY1", "FRY2", "FRY3", "FRY4", "FRY5", "FRZZ",
                         "PT20", "PT30", "PTZZ", "ES70", "ESZZ", "NO0B", "NOZZ")) %>% 
  pivot_wider(., names_from = c_resid, values_from = values) %>%
  mutate(DOM_SHARE = DOM/TOTAL,
         FOR_SHARE = FOR/TOTAL,
         TURIST = factor(ifelse(DOM_SHARE > 0.5, 0, 1), levels = c(1, 0),
                         labels = c("Foreign Tourist", "Domestic Tourist")))
```
By plotting the latter variable, we were able to group together regions based on whether the majority of overnight stays in hotels were by domestic tourists or foreign tourists.

```{r Distribution of Tourist Overnight-Stay by Origin, width = "80%", fig.align='center'}
EU_plot_2 <- ggplot(data_nightstay) +
  geom_sf(aes(fill = TURIST, geometry = geometry)) +
  theme_map() +
  labs(x = NULL, y = NULL,
       title = "Distribution of Tourist Overnight-Stay by Origin",
       subtitle = "Europe - NUTS2 Level",
       caption = "Source: Eurostat")+
  guides(fill = guide_legend(title = "Tourist Type:")) +
  theme(legend.position = "bottom",
        plot.title = element_text(face = "bold"))

plot(EU_plot_2)
```
Not surprisingly, these were the regions with the most famous "Instagrammable" destinations such as:

- Italy: Venice, Milan, Florence, or Rome,

- Spain: Barcelona and the Balearic Islands,

- France: Paris,

- Austria: ski hubs in the Alpine regions and Vienna,

- the capital region of Brussels, the Netherlands, Portugal, Ireland, and many other Central and Eastern European (CEE) countries,

- the coastal regions of Greece and Turkey (Antalya and Bodrum).

Overall, the plot conveys a picture of the main touristic hotspots of Europe where tourists from abroad mostly arrive, However it might be biased as it does not consider other touristic accommodations such as Airbnb, mostly used by young Europeans.

The plot for the continuous scale variable focused on the domestic dimension of tourism and represented the share of domestic tourist overnight stays in different European regions.

```{r Distribution of Domestic Tourist Overnight-stay, width = "80%", fig.align='center'}
EU_plot_3 <- ggplot(data_nightstay) +
  geom_sf(aes(fill = DOM_SHARE, geometry = geometry)) +
  theme_map() +
  labs(x = NULL, y = NULL,
       title = "Distribution of Domestic Tourist Overnight-stay",
       subtitle = "Europe - NUTS2 Level",
       caption = "Source: Eurostat") +
  theme(legend.position = "bottom",
        plot.title = element_text(face = "bold")) +
  scale_fill_viridis(option = "viridis",
                     direction = 1, 
                     name = "Share of Domestic Tourist Overnights",
                     guide = guide_colorbar(direction = "horizontal", 
                                            barheight = unit(2, units = "mm"),
                                            barwidth = unit(51, units = "mm"),
                                            draw.ulim = TRUE,
                                            title.position = "top"))

plot(EU_plot_3)
```

Besides stressing the point made by the previous map, this time we get more insights on the distribution of Domestic tourists in Europe. Germany appears to see a higher flow of in-country movement in its Bundesländer. So does some Italian regions of the eastern coast, which are notably more difficult to reach via international connections like Abruzzi and Molise or Calabria. Similarly, we notice a smaller share of foreigner's overnight stay in peripherical CEE countries' regions and Turkey, where the inland regions are mostly hosting domestic tourists.

## Storing visualizations
There are two conceptually different ways to store visualizations: raster-based and vector-based formats. 

Raster-based formats like PNG and JPEG store images as grids of pixels, making them suitable for complex color gradients and detailed images. However, they are resolution-dependent, which means they can lose quality when scaled up.

On the other hand, vector-based formats such as SVG and PDF store image data using mathematical formulas to define shapes, lines, and colors. This makes them ideal for visualizations with geometric shapes, charts, maps, and illustrations where scalability and high-quality printing are crucial. Unlike raster formats, vector graphics are resolution-independent and can be scaled without loss of quality.

For visualizations created using R and ggplot2, which inherently produce vector graphics, it is recommended to save them in vector-based formats like SVG or PDF. These formats maintain sharpness and clarity when scaled to any size, making them suitable for presentations, printing, and high-resolution displays. SVG is particularly useful for web-based graphics and interactive visualizations, while PDF is excellent for high-quality printing and cross-platform compatibility.

```{r Saving plots}
# Example on how to save the above-displayed plots:
ggsave("EU_plot_1.svg", plot = EU_plot_1, path = "./plot", device = "svg", 
       width = 30, height = 15, units = "cm")
ggsave("EU_plot_2.svg", plot = EU_plot_2, path = "./plot", device = "svg", 
       width = 30, height = 15, units = "cm")
ggsave("EU_plot_3.svg", plot = EU_plot_3, path = "./plot", device = "svg", 
       width = 30, height = 15, units = "cm")
```
\newpage

# Exercise D

## Comparison of support for Komorowski and Duda
```{r Support Duda vs Komorowsky, fig.align='center'}
df <- pol_pres15 %>% 
  mutate(Winner = factor(ifelse(II_Duda_share > 0.5, 1, 0), levels = c(1, 0), 
                         labels = c("Duda", "Komorowski")),
         Majority_votes_brkdwn =ifelse(II_Duda_share > 0.5, II_Duda_share, II_Komorowski_share))

PL_plot_1 <- ggplot(df) +
  geom_sf(aes(fill = Winner, alpha = Majority_votes_brkdwn, geometry = geometry)) +
  scale_fill_manual(values = c("Duda" = "red", "Komorowski" = "blue")) +
  scale_alpha(range = c(0.2, 1), guide = "none") +
  theme_map() +
  labs(x = NULL, y = NULL,
       title = "2015 Polish Presidential Election: Duda vs. Komorowski",
       subtitle = "Poland - Municipality Level",
       caption = "Source: PKW") +
  guides(fill=guide_legend(title = "Winner:")) +
  theme(
    plot.title = element_text(size = 11, face = "bold"),
    plot.subtitle = element_text(size = 10),
    legend.title = element_text(size = 10),
    legend.text = element_text(size = 10))

plot(PL_plot_1)
```

The provided R code generates a thematic map representing the outcomes of the second round of the 2015 Polish presidential elections at the municipality level. The data is grouped based on whether the winning candidate in each municipality was Duda or Komorowski. The plot uses different shades of red or blue (representing Duda or Komorowski, respectively) to indicate varying levels of majority support for the respective candidate.

The transparency of the colors also varies to reflect the degree of majority/support for the winning candidate in each municipality. Darker shades indicate a higher level of majority/support, while lighter shades represent a lower level of majority/support. This additional dimension helps visually emphasize areas where the winning candidate had a more significant lead in terms of voter share.

## Postal voting envelopes anomalies
Three types of anomalies are identified:

- `anomaly_invalid`: Checks if there are more invalid voting papers than postal voting envelopes received in either round of voting.

- `anomaly_spelling`: Identifies anomalies related to discrepancies in the number of invalid voting papers and specific errors on postal voting envelopes, such as missing declarations, signatures, voting envelopes, or signs of envelope opening.

- `anomaly_count`: Detects anomalies in the count of voting envelopes placed in the ballot box versus the number of voting papers taken from envelopes in either round of voting.


```{r Anomalies PVE, fig.align='center'}
data <- pol_pres15 %>%
  mutate(anomaly_invalid = ifelse(I_invalid_voting_papers > I_postal_voting_envelopes_received |
                                  II_invalid_voting_papers > II_postal_voting_envelopes_received, 1, 0),
         anomaly_spelling = ifelse(I_invalid_voting_papers > 0 &
                                   I_PVE_of_which_no_declaration == 0 &
                                   I_PVE_of_which_no_signature == 0 &
                                   I_PVE_of_which_no_voting_envelope == 0 &
                                   I_PVE_of_which_voting_envelope_open == 0 |
                                   II_invalid_voting_papers > 0 &
                                   II_PVE_of_which_no_declaration == 0 &
                                   II_PVE_of_which_no_signature == 0 &
                                   II_PVE_of_which_no_voting_envelope == 0 &
                                   II_PVE_of_which_voting_envelope_open == 0, 1, 0),
         anomaly_count = ifelse(I_voting_envelopes_placed_in_ballot_box != I_of_which_voting_papers_taken_from_voting_envelopes |
                                II_voting_envelopes_placed_in_ballot_box != II_of_which_voting_papers_taken_from_voting_envelopes, 1,0),
         anomaly = ifelse(anomaly_invalid == 1 | anomaly_spelling == 1 |
                          anomaly_count == 1, anomaly_invalid + anomaly_spelling + anomaly_count, 0)) %>% 
  mutate(anomaly_type = case_when(
    anomaly_invalid == 0 & anomaly_spelling == 0 & anomaly_count == 0 ~ "None",
    anomaly_invalid == 1 & anomaly_spelling == 0 & anomaly_count == 0 ~ "Invalid Anomaly",
    anomaly_invalid == 0 & anomaly_spelling == 1 & anomaly_count == 0 ~ "Spelling Anomaly",
    anomaly_invalid == 0 & anomaly_spelling == 0 & anomaly_count == 1 ~ "Extraction Anomaly",
    anomaly_invalid == 1 & anomaly_spelling == 1 & anomaly_count == 0 ~ "Invalid + Spelling Anomaly",
    anomaly_invalid == 1 & anomaly_spelling == 0 & anomaly_count == 1 ~ "Invalid + Extraction Anomaly",
    anomaly_invalid == 0 & anomaly_spelling == 1 & anomaly_count == 1 ~ "Extraction + Spelling Anomaly"
  ))

# Need x and y coordinates for point, thus convert the geometry column to sf object
data_sf <- st_as_sf(data, wkt = "geometry")
centroid <- st_centroid(data_sf)
data_with_centroid <- cbind(data, st_coordinates(centroid))

PL_plot_2 <- ggplot(data_with_centroid) +
  geom_sf(fill = "white") +
  geom_point(data = subset(data_with_centroid, anomaly > 0), aes(x = X, y = Y, color = as.factor(anomaly_type), size = as.factor(anomaly)), alpha = 0.6) +
  theme_void() +
  labs(title = "2015 Polish Presidential Election: anomalies in PVE",
       subtitle = "Poland - Municipality Level",
       caption = "Data source: PKW",
       color = "Anomaly Type:",
       size = "Anomaly Count:") +
  theme(
    plot.title = element_text(size = 11, face = "bold"),
    legend.text = element_text(size = 10))

plot(PL_plot_2)
```
Anomalies are represented as points `geom_point()` on the map, with each point's color indicating the type of anomaly and size representing the how many anomalies types were overall detected.In this way, one can highlight areas where specific types of anomalies or their combinations were observed more frequently.

By visually exploring anomalies in the handling of voting materials, it appears that this was a widespread problem, involving several municipalities. The majority of anomalies seems to have happened in the center-south part of the country which was where Duda won, as highlighted by the previous plot. 

Notice that among the three anomalies identified, the one related to spelling relies on a specific assumption. This assumption presumes that all potential reasons for invalidity were documented in the dataset, leading to the anomaly being the higher count of invalid PVEs despite their return with a signed declaration and sealed voting envelope. However, it is crucial to consider that there may be additional, unrecorded issues contributing to this discrepancy, such as misspelling the candidate's name (reason of the variable name). Validating this assumption requires further material, information, or contextual details.

## Turnout for each election round
For the final visualization, employing `tm_shape()` function, Turnout share in the first and second round of the presidential election was plotted. We made use of the `tm_facets` specification to combine in a single plot both heatmaps.

```{r Turnout, fig.align='center'}
ds <- pol_pres15 %>%
  pivot_longer(cols = c(I_turnout, II_turnout), names_to = "election", values_to = "turnout")

PL_plot_3 <- tm_shape(ds) +
  tm_fill(col = "turnout", title = "Turnout Share:", palette = "plasma" ) +
  tm_borders(invisible()) +
  tm_facets(by = "election", free.scales = FALSE) +
  tm_layout(main.title = "Turnout Comparison between I and II round",
            title.position = c("center", "top"),
            frame = TRUE) +
  tm_credits("Source: PKW", position = "left")

PL_plot_3
```

Overall, it appears that in the second round there was a higher public involvement. In rural areas this was less stronger than in the more condensed urban areas, where participation peaked as far as reaching almost 80%.

# Additional
```{r}
sessionInfo()
```

